{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDEExiAk4fLb"
   },
   "source": "# Fine-tune Gemma 2b using LoRA"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1q6-W_mKIT-"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_EdOg9DPK6Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "from utils import preprocess_qa_data\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "COLAB = True\n",
    "KAGGLE = False\n",
    "DOWNLOAD_DATA = True\n",
    "SAVE_TO_GITHUB = False\n",
    "GIT_REPOSITORY = \"CS221-project\"\n",
    "FILE_NAME = \"colab_tuning.ipynb\"\n",
    "\n",
    "if COLAB:\n",
    "    PARENT_DIRECTORY_PATH = \"/content\"\n",
    "    # In case you want to clone in your drive:\n",
    "    PARENT_DIRECTORY_PATH = \"/content/drive/MyDrive\"\n",
    "    PROJECT_PATH = PARENT_DIRECTORY_PATH + \"/\" + GIT_REPOSITORY\n",
    "    %cd \"{PARENT_DIRECTORY_PATH}\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if COLAB:\n",
    "    %cd /content\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if COLAB:\n",
    "    import json\n",
    "\n",
    "    with open(f\"{PARENT_DIRECTORY_PATH}/Git/git.json\", \"r\") as f:\n",
    "        parsed_json = json.load(f)\n",
    "\n",
    "    GIT_USER_NAME = parsed_json[\"GIT_USER_NAME\"]\n",
    "    GIT_TOKEN = parsed_json[\"GIT_TOKEN\"]\n",
    "    GIT_USER_EMAIL = parsed_json[\"GIT_USER_EMAIL\"]\n",
    "\n",
    "    GIT_PATH = (\n",
    "        f\"https://{GIT_TOKEN}@github.com/{GIT_USER_NAME}/{GIT_REPOSITORY}.git\"\n",
    "    )\n",
    "\n",
    "    %cd \"{PARENT_DIRECTORY_PATH}\"\n",
    "\n",
    "    !git clone \"{GIT_PATH}\"  # Clone the github repository\n",
    "\n",
    "    %cd \"{PROJECT_PATH}\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if COLAB:\n",
    "    import os\n",
    "    os.environ[\"KAGGLE_CONFIG_DIR\"] = f\"{PARENT_DIRECTORY_PATH}/Kaggle/kaggle.json\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if SAVE_TO_GITHUB:\n",
    "    !git add {FILE_NAME}\n",
    "    !git config --global user.email {GIT_USER_EMAIL}\n",
    "    !git config --global user.name {GIT_USER_NAME}\n",
    "    !git commit -am \"update {FILE_NAME}\"\n",
    "    !git push"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Set environment variables"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
    "# os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
    "\n",
    "# Read the kaggle.json file\n",
    "# with open(\"kaggle.json\") as f:\n",
    "#     kaggle_info = json.load(f)\n",
    "\n",
    "# Set the environment variables\n",
    "# os.environ[\"KAGGLE_USERNAME\"] = kaggle_info[\"username\"]\n",
    "# os.environ[\"KAGGLE_KEY\"] = kaggle_info[\"key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuEUAKJW1QkQ"
   },
   "source": "### Install dependencies"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1eeBtYqJsZPG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716225222708,
     "user_tz": -60,
     "elapsed": 63265,
     "user": {
      "displayName": "Aline Menezes",
      "userId": "05683124779900998129"
     }
    },
    "outputId": "0dc50526-a8aa-4d16-b340-afbac72e1477",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m515.3/515.3 kB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m950.8/950.8 kB\u001B[0m \u001B[31m9.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.2/5.2 MB\u001B[0m \u001B[31m19.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m589.8/589.8 MB\u001B[0m \u001B[31m2.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.3/5.3 MB\u001B[0m \u001B[31m74.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m79.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.5/5.5 MB\u001B[0m \u001B[31m103.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m39.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m311.2/311.2 kB\u001B[0m \u001B[31m33.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGLS-l5TxIR4"
   },
   "source": "### Select a backend"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yn5uy8X8sdD0"
   },
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZs8XXqUKRmi"
   },
   "source": "### Import packages"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYHyPUA9hKTf"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9T7xe_jzslv4"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45UpBDfBgf0I"
   },
   "source": [
    "Preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiS-KU9osh_N"
   },
   "outputs": [],
   "source": [
    "with open(\"qa_data.txt\") as file:\n",
    "        content = file.read()\n",
    "data = preprocess_qa_data(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RCE3fdGhDE5"
   },
   "source": "## Load Model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz5zLEyLstfn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716225546016,
     "user_tz": -60,
     "elapsed": 31019,
     "user": {
      "displayName": "Aline Menezes",
      "userId": "05683124779900998129"
     }
    },
    "outputId": "d8d07c82-c87a-44c4-921a-101420596343",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'task.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'preprocessor.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n",
      "Attaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Colab notebook...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mTokenizer (type)                                  \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m                                            Vocab #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001B[38;5;33mGemmaTokenizer\u001B[0m)                   │                                             \u001B[38;5;34m256,000\u001B[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"gemma_causal_lm\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                 \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m        Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to              \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001B[38;5;33mInputLayer\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)              │               \u001B[38;5;34m0\u001B[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)              │               \u001B[38;5;34m0\u001B[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)        │   \u001B[38;5;34m2,506,172,416\u001B[0m │ padding_mask[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],        │\n",
       "│ (\u001B[38;5;33mGemmaBackbone\u001B[0m)               │                           │                 │ token_ids[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256000\u001B[0m)      │     \u001B[38;5;34m524,288,000\u001B[0m │ gemma_backbone[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n",
       "│ (\u001B[38;5;33mReversibleEmbedding\u001B[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m2,506,172,416\u001B[0m (9.34 GB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m2,506,172,416\u001B[0m (9.34 GB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_L6A5J-1QgC"
   },
   "source": "## Inference before fine tuning"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVLXadptyo34"
   },
   "source": [
    "### Probability Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwQz3xxxKciD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716225571138,
     "user_tz": -60,
     "elapsed": 20048,
     "user": {
      "displayName": "Aline Menezes",
      "userId": "05683124779900998129"
     }
    },
    "outputId": "871d4e0a-e707-4362-cea9-aca3a6715384",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Instruction:\n",
      "What is the difference between permutations and combinations?\n",
      "\n",
      "Response:\n",
      "There are 16 ways to choose 3 people from a group of 6.\n",
      "There are 12 ways to choose 3 people without repetition from a group of 9.\n",
      "There are 48 ways to choose 3 people with repetition from a group of 6.\n",
      "There are 10 ways to choose 3 people from a group of 3 with repetition.\n",
      "The answer is the last one.\n",
      "The number of combinations is the same as the number of permutations with repetition.\n",
      "There are 48 combinations of 3 people in a group of 6 with repetition.\n",
      "\n",
      "Explanation:\n",
      "\n",
      "1. There are 16 ways to choose 3 people from a group of 6.\n",
      "\n",
      "2. There are 12 ways to choose 3 people without repetition from a group of 9.\n",
      "\n",
      "3. There are 48 ways to choose 3 people with repetition from a group of 6.\n",
      "There are 10 ways to choose 3 people from a group of 3 with repetition.\n",
      "\n",
      "4.\n",
      "\n",
      "The number of permutations is the same as the number of combinations.\n",
      "\n",
      "The number of permutations with\n"
     ]
    }
   ],
   "source": [
    "template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
    "\n",
    "prompt = template.format(\n",
    "    instruction=\"What is the difference between permutations and combinations?\",\n",
    "    response=\"\",\n",
    ")\n",
    "\n",
    "sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
    "gemma_lm.compile(sampler=sampler)\n",
    "print(gemma_lm.generate(prompt, max_length=256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQ74Zz_S0iVv"
   },
   "source": [
    "### Supervised Learning Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lorJMbsusgoo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716225581790,
     "user_tz": -60,
     "elapsed": 6400,
     "user": {
      "displayName": "Aline Menezes",
      "userId": "05683124779900998129"
     }
    },
    "outputId": "7acc803e-3d88-4174-e6e4-48457b1684c5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Instruction:\n",
      "What is Supervised Learning?\n",
      "\n",
      "Response:\n",
      "Supervised learning is a type of machine learning in which the algorithm learns to map from a data set to a class label. In other words, it takes an input and produces a predicted output. The algorithm is given a set of training data with known class labels (e.g. 0 and 1 for binary classification). The goal is for the algorithm to predict the class label of new input data with the same accuracy as the training data.\n",
      "\n",
      "Supervised learning is used in many fields, including computer vision, natural language processing, and medical imaging. The most common supervised learning algorithms are linear models, decision trees, and artificial neural networks.\n"
     ]
    }
   ],
   "source": [
    "prompt = template.format(\n",
    "    instruction=\"What is Supervised Learning?\",\n",
    "    response=\"\",\n",
    ")\n",
    "print(gemma_lm.generate(prompt, max_length=256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pt7Nr6a7tItO"
   },
   "source": "## LoRA Fine-tuning"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCucu6oHz53G",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716225591772,
     "user_tz": -60,
     "elapsed": 536,
     "user": {
      "displayName": "Aline Menezes",
      "userId": "05683124779900998129"
     }
    },
    "outputId": "5858049f-ce60-4c15-cc4a-07416a493585",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mTokenizer (type)                                  \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m                                            Vocab #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001B[38;5;33mGemmaTokenizer\u001B[0m)                   │                                             \u001B[38;5;34m256,000\u001B[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"gemma_causal_lm\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                 \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m        Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to              \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001B[38;5;33mInputLayer\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)              │               \u001B[38;5;34m0\u001B[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)              │               \u001B[38;5;34m0\u001B[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)        │   \u001B[38;5;34m2,507,536,384\u001B[0m │ padding_mask[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],        │\n",
       "│ (\u001B[38;5;33mGemmaBackbone\u001B[0m)               │                           │                 │ token_ids[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256000\u001B[0m)      │     \u001B[38;5;34m524,288,000\u001B[0m │ gemma_backbone[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n",
       "│ (\u001B[38;5;33mReversibleEmbedding\u001B[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m2,507,536,384\u001B[0m (9.34 GB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (9.34 GB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,363,968\u001B[0m (5.20 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m2,506,172,416\u001B[0m (9.34 GB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Enable LoRA for the model and set the LoRA rank to 4.\n",
    "gemma_lm.backbone.enable_lora(rank=4)\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Peq7TnLtHse",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716228975918,
     "user_tz": -60,
     "elapsed": 3373697,
     "user": {
      "displayName": "Aline Menezes",
      "userId": "05683124779900998129"
     }
    },
    "outputId": "8be74883-328e-46e7-d1dc-6521b786a45c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m2346/2346\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3372s\u001B[0m 1s/step - loss: 0.4749 - sparse_categorical_accuracy: 0.6215\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c1fe4667c70>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Limit the input sequence length to 512 (to control memory usage).\n",
    "gemma_lm.preprocessor.sequence_length = 512\n",
    "# Use AdamW (a common optimizer for transformer models).\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "# Exclude layernorm and bias terms from decay.\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "gemma_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizer,\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "gemma_lm.fit(data, epochs=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the fine-tuned model\n",
    "gemma_lm.save(\"/content/drive/MyDrive/Colab Notebooks/cs221/fine_tuned_model_1.keras\")\n"
   ],
   "metadata": {
    "id": "3f_W8l02mukQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0lHxEDX03gp"
   },
   "outputs": [],
   "source": [
    "# Uncomment the line below if you want to enable mixed precision training on GPUs\n",
    "# keras.mixed_precision.set_global_policy('mixed_bfloat16')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the fine-tuned model\n",
    "\n",
    "# loaded_model = keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/cs221/fine_tuned_model_1.keras\")\n",
    "\n",
    "# Use the loaded model for generation\n",
    "# prompt = template.format(\n",
    "#     instruction=\"What is Supervised Learning?\",\n",
    "#     response=\"\",\n",
    "# )\n",
    "# sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
    "# loaded_model.compile(sampler=sampler)\n",
    "# generated_text = loaded_model.generate(prompt, max_length=256)\n",
    "# print(generated_text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yTLaxefSnBFb",
    "executionInfo": {
     "status": "error",
     "timestamp": 1716229634662,
     "user_tz": -60,
     "elapsed": 11468,
     "user": {
      "displayName": "Aline Menezes",
      "userId": "05683124779900998129"
     }
    },
    "outputId": "56e065e5-5ff5-4429-d4e1-291994099a6a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 4194304256 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:         8B\n              constant allocation:         0B\n        maybe_live_out allocation:    1.95GiB\n     preallocated temp allocation:    3.91GiB\n  preallocated temp fragmentation:         0B (0.00%)\n                 total allocation:    5.86GiB\n              total fragmentation:       240B (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 1.95GiB\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/mul\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: f32[256000,2048]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 1000.00MiB\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: u32[262144000]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 1000.00MiB\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: u32[262144000]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 1000.00MiB\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: u32[262144000]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 1000.00MiB\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: u32[262144000]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 16B\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: (u32[262144000], u32[262144000])\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 16B\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: (u32[262144000], u32[262144000])\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 8B\n\t\tEntry Parameter Subshape: u32[2]\n\t\t==========================\n\n",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-e3111d28925f>\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Load the fine-tuned model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# loaded_model = keras.models.load_model(\"fine_tuned_model_1.h5\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mloaded_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/content/drive/MyDrive/Colab Notebooks/cs221/fine_tuned_model_1.keras\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# Use the loaded model for generation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001B[0m in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[1;32m    174\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    175\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mis_keras_zip\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 176\u001B[0;31m         return saving_lib.load_model(\n\u001B[0m\u001B[1;32m    177\u001B[0m             \u001B[0mfilepath\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    178\u001B[0m             \u001B[0mcustom_objects\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcustom_objects\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001B[0m in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[1;32m    150\u001B[0m             )\n\u001B[1;32m    151\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 152\u001B[0;31m             return _load_model_from_fileobj(\n\u001B[0m\u001B[1;32m    153\u001B[0m                 \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcustom_objects\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcompile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msafe_mode\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    154\u001B[0m             )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001B[0m in \u001B[0;36m_load_model_from_fileobj\u001B[0;34m(fileobj, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[1;32m    168\u001B[0m         \u001B[0;31m# Construct the model from the configuration file in the archive.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    169\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mObjectSharingScope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 170\u001B[0;31m             model = deserialize_keras_object(\n\u001B[0m\u001B[1;32m    171\u001B[0m                 \u001B[0mconfig_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcustom_objects\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msafe_mode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msafe_mode\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m             )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001B[0m in \u001B[0;36mdeserialize_keras_object\u001B[0;34m(config, custom_objects, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    716\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mcustom_obj_scope\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msafe_mode_scope\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    717\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 718\u001B[0;31m             \u001B[0minstance\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_config\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minner_config\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    719\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    720\u001B[0m             raise TypeError(\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras_nlp/src/models/task.py\u001B[0m in \u001B[0;36mfrom_config\u001B[0;34m(cls, config)\u001B[0m\n\u001B[1;32m    146\u001B[0m         \u001B[0;31m# vanilla `keras.Model`. We override it to get a subclass instance back.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m\"backbone\"\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mconfig\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"backbone\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 148\u001B[0;31m             \u001B[0mconfig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"backbone\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeserialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"backbone\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    149\u001B[0m         if \"preprocessor\" in config and isinstance(\n\u001B[1;32m    150\u001B[0m             \u001B[0mconfig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"preprocessor\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/__init__.py\u001B[0m in \u001B[0;36mdeserialize\u001B[0;34m(config, custom_objects)\u001B[0m\n\u001B[1;32m    164\u001B[0m         \u001B[0mA\u001B[0m \u001B[0mKeras\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0minstance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    165\u001B[0m     \"\"\"\n\u001B[0;32m--> 166\u001B[0;31m     obj = serialization_lib.deserialize_keras_object(\n\u001B[0m\u001B[1;32m    167\u001B[0m         \u001B[0mconfig\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m         \u001B[0mcustom_objects\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcustom_objects\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001B[0m in \u001B[0;36mdeserialize_keras_object\u001B[0;34m(config, custom_objects, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    716\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mcustom_obj_scope\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msafe_mode_scope\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    717\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 718\u001B[0;31m             \u001B[0minstance\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_config\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minner_config\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    719\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    720\u001B[0m             raise TypeError(\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras_nlp/src/models/backbone.py\u001B[0m in \u001B[0;36mfrom_config\u001B[0;34m(cls, config)\u001B[0m\n\u001B[1;32m    141\u001B[0m         \u001B[0;31m# The default `from_config()` for functional models will return a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m         \u001B[0;31m# vanilla `keras.Model`. We override it to get a subclass instance back.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 143\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    144\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mclassproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras_nlp/src/models/gemma/gemma_backbone.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, vocabulary_size, num_layers, num_query_heads, num_key_value_heads, hidden_dim, intermediate_dim, head_dim, layer_norm_epsilon, dropout, dtype, **kwargs)\u001B[0m\n\u001B[1;32m    146\u001B[0m             \u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"float32\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"padding_mask\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m         )\n\u001B[0;32m--> 148\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoken_embedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoken_id_input\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    149\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_dim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    150\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mtransformer_layer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransformer_layers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    120\u001B[0m             \u001B[0;31m# To get the full stack trace, call:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    121\u001B[0m             \u001B[0;31m# `keras.config.disable_traceback_filtering()`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 122\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    123\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m             \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras_nlp/src/layers/modeling/reversible_embedding.py\u001B[0m in \u001B[0;36mbuild\u001B[0;34m(self, inputs_shape)\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mbuild\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs_shape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 108\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtie_weights\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/random.py\u001B[0m in \u001B[0;36mnormal\u001B[0;34m(key, shape, dtype)\u001B[0m\n\u001B[1;32m    709\u001B[0m   \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcanonicalize_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    710\u001B[0m   \u001B[0mshape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_named_shape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 711\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0m_normal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    712\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    713\u001B[0m \u001B[0;34m@\u001B[0m\u001B[0mpartial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstatic_argnums\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 4194304256 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:         8B\n              constant allocation:         0B\n        maybe_live_out allocation:    1.95GiB\n     preallocated temp allocation:    3.91GiB\n  preallocated temp fragmentation:         0B (0.00%)\n                 total allocation:    5.86GiB\n              total fragmentation:       240B (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 1.95GiB\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/mul\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: f32[256000,2048]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 1000.00MiB\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: u32[262144000]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 1000.00MiB\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: u32[262144000]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 1000.00MiB\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: u32[262144000]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 1000.00MiB\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: u32[262144000]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 16B\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: (u32[262144000], u32[262144000])\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 16B\n\t\tOperator: op_name=\"jit(_normal)/jit(main)/jit(_normal_real)/jit(_uniform)/threefry2x32\" source_file=\"/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/random.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: (u32[262144000], u32[262144000])\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 8B\n\t\tEntry Parameter Subshape: u32[2]\n\t\t==========================\n\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yd-1cNw1dTn"
   },
   "source": "## Inference after fine-tuning"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H55JYJ1a1Kos"
   },
   "source": [
    "### Probability Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7cDJHy8WfCB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716229476321,
     "user_tz": -60,
     "elapsed": 13636,
     "user": {
      "displayName": "Aline Menezes",
      "userId": "05683124779900998129"
     }
    },
    "outputId": "bad71b96-e357-4156-cefe-67cd4f26dff1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Instruction:\n",
      "What is the difference between permutations and combinations?\n",
      "\n",
      "Response:\n",
      "Combinations are a special type of permutation, where order does not matter. The order of the elements in the combination matters, but the total number of possible combinations (i.e., the cardinality) is the same. Permutations are combinations where order matters and the total number of possible permutations is different for each combination, even when the combination size (number of elements) is the same.\n"
     ]
    }
   ],
   "source": [
    "template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
    "prompt = template.format(\n",
    "    instruction=\"What is the difference between permutations and combinations?\",\n",
    "    response=\"\",\n",
    ")\n",
    "sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
    "gemma_lm.compile(sampler=sampler)\n",
    "print(gemma_lm.generate(prompt, max_length=256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7nVd8Mi1Yta"
   },
   "source": [
    "### Supervised Learning Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-2sYl2jqwl7",
    "outputId": "389024a6-c6c0-4417-b925-7133edd762f7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716229516171,
     "user_tz": -60,
     "elapsed": 6372,
     "user": {
      "displayName": "Aline Menezes",
      "userId": "05683124779900998129"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Instruction:\n",
      "What is Supervised Learning?\n",
      "\n",
      "Response:\n",
      "Supervised Learning refers to the learning of a function or model that can accurately predict the outcome of a dependent variable based on a set of input variables. In supervised learning, the input variables are known as features and the output variable is the dependent variable, which is used to predict the value of some other variable. The supervised learning problem is formulated by specifying a function f that maps the input features to the output value. The goal is to learn the function f by training the model with a set of examples, where the examples are pairs of inputs and outputs.\n"
     ]
    }
   ],
   "source": [
    "prompt = template.format(\n",
    "    instruction=\"What is Supervised Learning?\",\n",
    "    response=\"\",\n",
    ")\n",
    "print(gemma_lm.generate(prompt, max_length=256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8kFG12l0mVe"
   },
   "source": [
    "To get better responses from the fine-tuned model, you can experiment with:\n",
    "\n",
    "1. Increasing the size of the fine-tuning dataset\n",
    "2. Training for more steps (epochs)\n",
    "3. Setting a higher LoRA rank\n",
    "4. Modifying the hyperparameter values such as `learning_rate` and `weight_decay`.\n",
    "\n",
    "Try Alpaca's configuration below\n",
    "\n",
    "| Hyperparameter | LLaMA-7B | LLaMA-13B |\n",
    "|----------------|----------|-----------|\n",
    "| Batch size     | 128      | 128       |\n",
    "| Learning rate  | 2e-5     | 1e-5      |\n",
    "| Epochs         | 3        | 5         |\n",
    "| Max length     | 512      | 512       |\n",
    "| Weight decay   | 0        | 0         |\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "CHlzum8jt_P1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716287706878,
     "user_tz": -60,
     "elapsed": 3,
     "user": {
      "displayName": "Aline Menezes",
      "userId": "05683124779900998129"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb",
     "timestamp": 1716151931541
    }
   ],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
